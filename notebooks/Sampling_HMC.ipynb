{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../widgets/config_check.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <api>\n",
    "import numpy as np\n",
    "from scipy.stats import norm, multivariate_normal\n",
    "from scipy.special import logsumexp\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Load classes and functions from the previous parts\n",
    "from jupyter_cms.loader import load_notebook\n",
    "smpl_intro = load_notebook('./Sampling_Intro.ipynb')\n",
    "smpl_rej = load_notebook('./Sampling_Rejection.ipynb')\n",
    "smpl_index = load_notebook('./Sampling_Index.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <api>\n",
    "import os\n",
    "path = os.getcwd()\n",
    "s = '/'\n",
    "pardir = s.join(path.split(s)[:-1])\n",
    "# Load widgets\n",
    "smpl_widgets = load_notebook(str(pardir + '/widgets/2D_sampling_widget.ipynb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smpl_index.help()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hamiltonian Monte Carlo (HMC)\n",
    "\n",
    "HMC uses gradient information to automatically find suitable directions. In this sense it fixes the above shortcoming that we have to specify a suitable proposal distribution in Metropolis-Hastings or adapted directions in multi-variate slice sampling. HMC makes clever use of a physical analogy and augments the state space with an auxiliary momentum vector $\\mathbf{p}$.\n",
    "\n",
    "Write the probability density $p(x)$ as\n",
    "$$ p(x) = \\frac{1}{Z} e^{-E(x)} $$\n",
    "and assume that the *energy* $E(x)$ as well as its gradient with respect to $x$ can be evaluated. Note that any $p(x)$ can be written in the above form by choosing $E(x) = - \\log p(x)$.\n",
    "\n",
    "Now, define the Hamiltonian $H(x) = E(x) + K(\\mathbf{p})$, i.e. the total (potential $E(x)$ plus kinetic $K(\\mathbf{p}) = \\frac{1}{2} \\mathbf{p}^t \\mathbf{p}$) energy of the system. It is well known from physics that the following dynamics conserves energy\n",
    "$$ \\begin{array}{lcl} \\dot{x} & = & \\mathbf{p} \\\\ \\dot{\\mathbf{p}} & = & - \\frac{\\partial}{\\partial x} E(x) \\end{array} $$\n",
    "\n",
    "Thus, we can sample from the joint density $p(x,\\mathbf{p}) \\propto e^{E(x)} e^{K(\\mathbf{p})}$ using Gibbs-like steps:\n",
    "\n",
    "1. Sample $\\mathbf{p} \\sim p(\\mathbf{p}|x) = \\mathcal{N}(0, \\mathbb{1})$\n",
    "2. Produce new state $x'$ by simulating the Hamiltonian dynamics for some time. Due to energy conservation the proposed $x'$ will always be accepted.\n",
    "\n",
    "Also volume is preserved by the Hamiltonian dynamics. This simplifies the algorithm considerably as no Jacobian adjustment is necessary to account for the change in volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <api>\n",
    "def integrate_H(xp, dE_dx, T, dt, method='euler'):\n",
    "    \"\"\"\n",
    "    Integrate the state xp for some time with the Hamiltonian H(x) = E(x) + K(x) \n",
    "    \"\"\"\n",
    "    x,p = xp\n",
    "    t = 0\n",
    "    while (t < T):\n",
    "        t += dt\n",
    "        if method=='euler':\n",
    "            gradE = dE_dx(x)\n",
    "            x += p*dt\n",
    "            p += - gradE*dt\n",
    "        else:\n",
    "            error('Unknown integration method')\n",
    "    return x,p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, Euler integration is very unstable for the Hamiltonian dynamics. Further, to ensure detailed balance we need to make sure that the integration scheme is reversible. In practice, a leap-frog integration is applied where half steps to the momentum are interleaved with an update to the state. In addition, leap-frog integration leads to a deterministic, discrete dynamics that is exactly invertible and preserves volume (as each update changes one variable based on the state of the other variable only, i.e. it is a simple shift in each variable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <api>\n",
    "def integrate_H(xp, dE_dx, T, dt, method='leap_frog'):\n",
    "    \"\"\"\n",
    "    Integrate the state xp for some time with the Hamiltonian H(x) = E(x) + K(x) \n",
    "    \"\"\"\n",
    "    x,p = np.copy(xp)\n",
    "    t = 0\n",
    "    while (t < T):\n",
    "        t += dt\n",
    "        if method=='euler':\n",
    "            gradE = dE_dx(x)\n",
    "            x += p*dt\n",
    "            p += - gradE*dt\n",
    "        elif method=='leap_frog':\n",
    "            p += - dE_dx(x)*dt/2\n",
    "            x += p*dt\n",
    "            p += - dE_dx(x)*dt/2\n",
    "        else:\n",
    "            error('Unknown integration method')\n",
    "    return x,p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demonstration on the 2-dimensional Gaussian example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# <api>\n",
    "# Simple numeric differentiation\n",
    "def grad (f, x):\n",
    "    eps = 1e-4\n",
    "    gradx = np.zeros_like(x)\n",
    "    for i in range(x.size):\n",
    "        dx = np.zeros_like(x)\n",
    "        dx[i] = 1\n",
    "        gradx[i] = (f(x + dx*eps/2) - f(x - dx*eps/2))/eps\n",
    "    return gradx\n",
    "\n",
    "def dE2d_dx(x):\n",
    "    return grad(lambda x: - smpl_rej.p2d.logpdf(x), x)\n",
    "\n",
    "x0 = np.array([1.5, 0]); p0 = np.array([0.1, -0.1])\n",
    "traj_euler = [(x0,p0)]; traj_leap_frog = [(x0,p0)]\n",
    "dt = 0.01\n",
    "for i in range(250):\n",
    "    traj_euler.append(integrate_H(traj_euler[-1], dE2d_dx, dt, dt, 'euler'))\n",
    "    traj_leap_frog.append(integrate_H(traj_leap_frog[-1], dE2d_dx, dt, dt, 'leap_frog'))\n",
    "traj_euler = np.array(traj_euler).squeeze(); traj_leap_frog = np.array(traj_leap_frog).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.contour(smpl_rej.X, smpl_rej.Y, smpl_rej.p2d.pdf(smpl_rej.XY));\n",
    "plt.plot(traj_euler[:,0,0], traj_euler[:,0,1], 'r-')\n",
    "plt.plot(traj_leap_frog[:,0,0], traj_leap_frog[:,0,1], 'b-');\n",
    "plt.axis([-3,3,-3,3])\n",
    "plt.legend(['Euler integration', 'leap-frog integration'])\n",
    "plt.xlabel('x', fontsize=15)\n",
    "plt.ylabel('y', fontsize=15)\n",
    "plt.title('Visualization of integration methods', fontsize=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, also the leap frog integration is not perfect and energy is not precisely conserved. Thus, the actual algorithm includes a Metropolis step which discards samples with lower energy to ensure that it samples from the correct distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <api>\n",
    "class HMC (smpl_intro.Sampling):\n",
    "    def __init__(self, x, E, dE_dx=None, Tau=42, dtau=0.04):\n",
    "        self.x = x\n",
    "        self.E = E\n",
    "        if dE_dx is None:\n",
    "            dE_dx = lambda x: grad(E, x)\n",
    "        self.dE_dx = dE_dx\n",
    "        self.Tau = Tau\n",
    "        self.dtau = dtau\n",
    "        \n",
    "    def _H (self, x, p):\n",
    "        return self.E(x) + 0.5*np.dot(p.T, p)\n",
    "        \n",
    "    def sample (self):\n",
    "        # Gibbs step for momentum\n",
    "        x = self.x\n",
    "        p = np.random.normal(size=x.shape)\n",
    "        H = self._H(x, p)\n",
    "        \n",
    "        # Simulate dynamics\n",
    "        xnew, pnew = integrate_H((x,p), self.dE_dx, self.Tau*self.dtau, self.dtau, 'leap_frog')\n",
    "        Hnew = self._H(xnew, pnew)\n",
    "        \n",
    "        # Metropolis step\n",
    "        if np.log(np.random.uniform()) < H - Hnew: # Remember: H = - logp\n",
    "            self.x = xnew\n",
    "        return self.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sampling = HMC(np.array([1.5,0]), lambda x: - smpl_rej.p2d.logpdf(x))\n",
    "\n",
    "samples = [sampling.sample() for _ in range(250)]\n",
    "plt.plot(np.array(samples)[:,0], np.array(samples)[:,1], 'r-')\n",
    "plt.contour(smpl_rej.X, smpl_rej.Y, smpl_rej.p2d.pdf(smpl_rej.XY));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "widget = smpl_widgets.SamplingWidget(method='HMC', target='MN')\n",
    "widget.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": "7aa720f648094a448ba9eda02377468b",
   "lastKernelId": "1b054203-2a95-4d99-b413-539e9da55e7f"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
