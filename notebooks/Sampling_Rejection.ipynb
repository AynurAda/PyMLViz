{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run ../widgets/config_check.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <api>\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import multivariate_normal\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Load classes and functions from the previous parts\n",
    "from jupyter_cms.loader import load_notebook\n",
    "smpl_intro = load_notebook('./Sampling_Intro.ipynb')\n",
    "smpl_index = load_notebook('./Sampling_Index.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smpl_index.help()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rejection sampling\n",
    "\n",
    "The next sampling method is less efficient, but more general in the sense that it can be used even if the normalization constant of the desired density $p(x)$ is unavailable.\n",
    "\n",
    "It is based on the idea that a sample at position $x$ should be drawn with probability $p(x)$, i.e. the height under the graph of $x$. Thus, a sample can be drawn using two random numbers as follows:\n",
    "\n",
    "* Draw a sample $x$ from some distribution $q(x)$\n",
    "* Draw a uniform number $u$ between 0 and $c q(x)$:\n",
    "  - If $u < p(x)$ return the sample $x$\n",
    "  - Else discard $x$ and repeat\n",
    "  \n",
    "Here, it is assumed that samples from $q(x)$ can be drawn efficiently. Further, the scaling constant $c$ must be choosen such that $c q(x) \\geq p(x) \\quad \\forall x$. The plot below illustrates the idea for the Gaussian distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <api>\n",
    "def p(x):\n",
    "    \"\"\"\n",
    "    Unnormalized density of the standard Gaussian\n",
    "    \"\"\"\n",
    "    return np.exp(-0.5*x**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "q = norm(loc=0, scale=2)\n",
    "x = np.arange(-5,5,0.01)\n",
    "plt.plot(x, p(x), 'b-', x, 5.1*q.pdf(x), 'g-')\n",
    "plt.xlabel('x', fontsize=15)\n",
    "plt.ylabel('Unnormalized probability', fontsize=15)\n",
    "plt.legend(['Density p(x)', 'Envelope c*q(x)'], fontsize=10, loc=1)\n",
    "plt.title('Illustration of proposal distribution', fontsize=15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#api\n",
    "class RejectionSampling (smpl_intro.Sampling):\n",
    "    def __init__ (self, p, q, c):\n",
    "        \"\"\"\n",
    "        q is assumed to support sampling q.rvs and density evaluation q.pdf\n",
    "        \"\"\"\n",
    "        self.p = p\n",
    "        self.q = q\n",
    "        self.c = c\n",
    "        self.tries = 0\n",
    "        self.samples = 0\n",
    "        self.last_approved = [0,0]\n",
    "\n",
    "    def sample (self):\n",
    "        while True:\n",
    "            self.tries += 1\n",
    "            x = self.q.rvs()\n",
    "            u = np.random.uniform(low=0, high=self.c*self.q.pdf(x))\n",
    "            if u < self.p(x):\n",
    "                self.samples += 1\n",
    "                return x\n",
    "            \n",
    "    def sample_all (self):\n",
    "        while True:\n",
    "            self.tries += 1\n",
    "            x = self.q.rvs()\n",
    "            u = np.random.uniform(low=0, high=self.c*self.q.pdf(x))\n",
    "            if u < self.p(x):\n",
    "                self.samples += 1\n",
    "                self.last_approved = x\n",
    "                return [x,x]\n",
    "            else:\n",
    "                return [self.last_approved, x]\n",
    "            \n",
    "    def __str__ (self):\n",
    "        return \"Rejection sampling: %d tries for %d samples\" % (self.tries, self.samples)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sampling = RejectionSampling(p=p, q=norm(loc=0, scale=2), c=5.1)\n",
    "\n",
    "smpl_intro.show_sampling(sampling, plotter=smpl_intro.gauss_hist, \n",
    "                    f_exp=lambda x: np.power(x,2), true_exp=1.0)\n",
    "print (sampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rejection sampling tends to work well, if a distribution $q(x)$ which closely approximates $p(x)$ from above can be found. Otherwise, the area between the curves will be large leading to a high rejection rate. Especially in high dimensions this is a severe problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A standard example to illustrate the difficulties arising in high dimensions is a 2-dimensional Gaussian with high correlation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <api>\n",
    "p2d = multivariate_normal(mean=[0,0], cov=[[1, 0.99],[0.99, 1]])\n",
    "x = np.linspace(-3, 3, 200)\n",
    "y = np.linspace(-3, 3, 200)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "XY = np.empty(X.shape + (2,))\n",
    "XY[:,:,0] = X; XY[:,:,1] = Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.contour(X, Y, p2d.pdf(XY))\n",
    "plt.xlabel('x', fontsize=15)\n",
    "plt.ylabel('y', fontsize=15)\n",
    "plt.title('2D Gaussian', fontsize=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem now is that an isotropic distribution is not a good fit since the above density has two very different length scales. Having a tight fit between the sampling and target density becomes even more important in high dimensions.\n",
    "\n",
    "For the sake of argument, consider the problem of sampling from a multi-variate Gaussian with mean zero and diagonal covariance matrix $\\sigma_p^2 \\mathbf{I}_D$ where $\\mathbf{I}_D$ denotes the $D \\times D$ identity matrix. As a sampling density, we choose another Gaussian with covariance $\\sigma_q^2 \\mathbf{I}_D$. The condition, $c q \\geq p$ now requires that $\\sigma_q^2 \\geq \\sigma_p^2$ and the optimal (smallest) value of $c$ is found to be $\\left( \\frac{\\sigma_p}{\\sigma_q} \\right)^D$. Then, the acceptance probability is given by the ratio of volumes under $p(x)$ and $c q(x)$ which is just $\\frac{1}{c}$ since both distributions are normalized. Thus, the acceptance probability vanishes exponentially in $D$.\n",
    "\n",
    "**Exercise:** Illustrate this effect when $\\sigma_q$ exceeds $\\sigma_p$ by $1 \\%$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <api>\n",
    "def gauss_hist2d (ax, data, bins):\n",
    "    x = np.array(data)[:,0]\n",
    "    y = np.array(data)[:,1]\n",
    "    ax.hist2d(x, y, bins, normed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "q = multivariate_normal(mean=[0,0], cov=np.eye(2))\n",
    "sampling = RejectionSampling(p=p2d.pdf, q=q, c=p2d.pdf([0,0])/q.pdf([0,0]))\n",
    "\n",
    "### How can we draw the expectation for 2D data?\n",
    "smpl_intro.show_sampling(sampling, plotter=gauss_hist2d, exp=False)\n",
    "print(sampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a much higher rejection rate than in the 1-dimensional example above.\n",
    "\n",
    "The next example shows that rejection sampling fails, i.e. samples from the wrong distribution, if the condition $c q(x) \\geq p(x)$ is violated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sampling = RejectionSampling(p=p, q=norm(loc=0, scale=2), c=2)\n",
    "\n",
    "smpl_intro.show_sampling(sampling, plotter=smpl_intro.gauss_hist, \n",
    "                    f_exp=lambda x: np.power(x,2), true_exp=1.)\n",
    "\n",
    "print(sampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the empirical density of the samples with the desired distribution, it is clearly visible that values close to zero are under represented. Accordingly, the empirical expectation of $x^2$ is higher than it would be under the desired distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": "94ba4fbc912f4c338d342bb0c540cd5a",
   "lastKernelId": "112488ef-39e9-44f7-852b-6d35d60d6569"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
